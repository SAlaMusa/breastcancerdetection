{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOomlXJ/c6TJWih1WHkvw+X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SAlaMusa/breastcancerdetection/blob/main/ml/aipractice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q7WdAW3-P17c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the number of samples\n",
        "n_samples = 1000\n",
        "\n",
        "# Create a DataFrame with columns\n",
        "data = pd.DataFrame({\n",
        "    'Area': np.random.uniform(500, 5000, n_samples),  # Area in square feet\n",
        "    'Bedrooms': np.random.randint(1, 6, n_samples),  # Number of bedrooms\n",
        "    'Bathrooms': np.random.randint(1, 5, n_samples),  # Number of bathrooms\n",
        "    'Age': np.random.randint(1, 50, n_samples),  # Age of the property in years\n",
        "    'Location': np.random.choice(['Kicukiro', 'Gasabo', 'Nyarugenge', 'Kicukiro'], n_samples)  # Location in Kigali\n",
        "})\n",
        "\n",
        "# Generate the target variable (Price) based on other features\n",
        "data['Price'] = (data['Area'] * np.random.uniform(100, 300, n_samples)) + \\\n",
        "                (data['Bedrooms'] * np.random.uniform(50000, 100000, n_samples)) + \\\n",
        "                (data['Bathrooms'] * np.random.uniform(30000, 80000, n_samples)) - \\\n",
        "                (data['Age'] * np.random.uniform(5000, 20000, n_samples)) + \\\n",
        "                np.random.normal(0, 50000, n_samples)  # Add some noise\n",
        "\n",
        "# Save the dataset to a CSV file\n",
        "data.to_csv('kigali_homes.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('kigali_homes.csv')\n",
        "\n",
        "# One-hot encode the 'Location' column\n",
        "encoder = LabelEncoder()\n",
        "data['Location'] = encoder.fit_transform(data['Location'])\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "location_ohe = ohe.fit_transform(data[['Location']])\n",
        "data = data.drop('Location', axis=1)\n",
        "data = pd.concat([data, pd.DataFrame(location_ohe, columns=encoder.classes_)], axis=1)\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = data.drop('Price', axis=1)\n",
        "y = data['Price']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=3, learning_rate=0.1)\n",
        "\n",
        "# Train the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R-squared: {r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G2Ycz3aP6Hr",
        "outputId": "921114ee-00cf-40eb-afa1-a5f4ca918f9f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 65606639388.75736\n",
            "R-squared: 0.6312259505172093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3Jp4ZuDQMxS",
        "outputId": "18a879fd-229b-4e42-f591-a4c7e1b1a9df"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.34.0-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.11.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.34.0 watchdog-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "import streamlit as st\n",
        "\n",
        "# Create a synthetic dataset\n",
        "n_samples = 1000\n",
        "data = pd.DataFrame({\n",
        "    'Area': np.random.uniform(500, 5000, n_samples),\n",
        "    'Bedrooms': np.random.randint(1, 6, n_samples),\n",
        "    'Bathrooms': np.random.randint(1, 5, n_samples),\n",
        "    'Age': np.random.randint(1, 50, n_samples),\n",
        "    'Location': np.random.choice(['Kicukiro', 'Gasabo', 'Nyarugenge', 'Kicukiro'], n_samples)\n",
        "})\n",
        "\n",
        "data['Price'] = (data['Area'] * np.random.uniform(100, 300, n_samples)) + \\\n",
        "                (data['Bedrooms'] * np.random.uniform(50000, 100000, n_samples)) + \\\n",
        "                (data['Bathrooms'] * np.random.uniform(30000, 80000, n_samples)) - \\\n",
        "                (data['Age'] * np.random.uniform(5000, 20000, n_samples)) + \\\n",
        "                np.random.normal(0, 50000, n_samples)\n",
        "\n",
        "# Preprocess the data\n",
        "encoder = LabelEncoder()\n",
        "data['Location'] = encoder.fit_transform(data['Location'])\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "location_ohe = ohe.fit_transform(data[['Location']])\n",
        "data = data.drop('Location', axis=1)\n",
        "data = pd.concat([data, pd.DataFrame(location_ohe, columns=encoder.classes_)], axis=1)\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = data.drop('Price', axis=1)\n",
        "y = data['Price']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "param_dist = {\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'gamma': [0, 0.1, 0.2, 0.3],\n",
        "    'reg_lambda': [0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "# Create the XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Perform randomized search\n",
        "random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, n_iter=100, cv=5, scoring='r2', n_jobs=-1, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(f'Best hyperparameters: {random_search.best_params_}')\n",
        "\n",
        "# Evaluate the tuned model\n",
        "xgb_tuned = random_search.best_estimator_\n",
        "y_pred = xgb_tuned.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R-squared: {r2}')\n",
        "\n",
        "# Save the model\n",
        "xgb_tuned.save_model('kigali_homes_model.json')\n",
        "\n",
        "# Function to make predictions\n",
        "def predict_price(area, bedrooms, bathrooms, age, location):\n",
        "    # One-hot encode the location\n",
        "    location_encoded = encoder.transform([location])[0]\n",
        "    location_ohe = ohe.transform([[location_encoded]])\n",
        "    location_ohe = pd.DataFrame(location_ohe, columns=encoder.classes_)\n",
        "\n",
        "    # Create a DataFrame with the input features\n",
        "    data = pd.DataFrame([[area, bedrooms, bathrooms, age] + list(location_ohe.iloc[0])],\n",
        "                         columns=['Area', 'Bedrooms', 'Bathrooms', 'Age'] + list(encoder.classes_))\n",
        "\n",
        "    # Make the prediction\n",
        "    prediction = xgb_tuned.predict(data)[0]\n",
        "\n",
        "    return prediction\n",
        "\n",
        "# Streamlit app\n",
        "st.title('Simple Property Valuation')\n",
        "\n",
        "area = st.number_input('Area (square feet)', min_value=500, max_value=5000, step=100)\n",
        "bedrooms = st.number_input('Number of Bedrooms', min_value=1, max_value=5, step=1)\n",
        "bathrooms = st.number_input('Number of Bathrooms', min_value=1, max_value=4, step=1)\n",
        "age = st.number_input('Age of Property (years)', min_value=1, max_value=50, step=1)\n",
        "location = st.selectbox('Location', ['Kicukiro', 'Gasabo', 'Nyarugenge', 'Kicukiro'])\n",
        "\n",
        "if st.button('Predict Price'):\n",
        "    predicted_price = predict_price(area, bedrooms, bathrooms, age, location)\n",
        "    st.write(f'Predicted Price: {predicted_price:.2f} Rwandan Francs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFZXUQpGQJUB",
        "outputId": "c51e9e20-8159-4e7a-b25d-31cb75408134"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "2024-05-19 19:13:45.024 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-05-19 19:13:45.026 Session state does not function when running a script without `streamlit run`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'reg_lambda': 10, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.05, 'gamma': 0}\n",
            "Mean Squared Error: 76252884576.15233\n",
            "R-squared: 0.5608404671702852\n"
          ]
        }
      ]
    }
  ]
}